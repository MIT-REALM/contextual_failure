import re
from contextual_failure.utils.generation_models import GPT_response, count_total_tokens

"""
Implements language model agent. Takes trajectory rollout information upto a certain point. 
Asks Language model to provide a pair-wise ranking. 
"""
def generate_prompt(objects, reason):
    user_prompt = f"""You will be provides the analysis of YOLO Object detection on an image that was taken from the camera feed of CARLA simulator. The simulator is simulating a pedestrian crossing the road before a car infront of the ego car. There are two cars and one pedestrian in each image. 
                        The information provided:
                            1.List of objects detected: The list of objects detected by YOLO in the image. This list should have atleast one object from the 'objects to detect' list
                                'Objects to detect' list:
                                    1. one object with one of the following labels: 'car','truck',
                                    2. one object with one of the following labels: 'car', 'truck','bus','motorcycle','bicycle'
                                    3. one object with one of the following labels: 'person'
                            2.Reason: The reason is a brief explanation of the failure to detect all objects, if that happens, and is generated by a pre-trained GiT model in the form of captions for the image. 
                        We are looking to discover images where YOLO fails to detect an object due to bad light and/or large distance.  
                        Your goal is to assess if the reason provided corresponds to bad light and/or large distance. If the list of 'objects detected' has an object missing from the 'objects-to-detect' list, look at the reason. The reason can have other components as well, but it can 'only' be considered as bad light if atleast one of the
                        objects was failed to detect strictly due to bad light. Similarly, the reason can have other components as well, but it can 'only' be considered as large distance if 
                        the reason contains the phrase 'far away'. Follow the response instructions while responding. 
                        Response Instructions:
                            Respond should be an integer 0, 1, 2, 3 or 4:
                            0 indicating that atleast one object was missing from the 'objects to detect' list, but the reason provided does not correspond to bad light or large distance 
                            1 indicating that an object was not detected and the reason provided corresponds to bad light only. 
                            2 indicating that an object was not detected, and the reason corresponds to large distance only. 
                            3 indicating that an object was not detected, and the reason corresponds to both large distance and bad light. 
                            4 indicating all objects are detected. Do not provide explanation. 
                        Response format: Response:  [integer], where inteer = 0,1,2,3,4.
                        The list of objects detected and reason for incomplete detection for the image are as follows:
                            1. Objects detected: {objects}
                            2. Reason: {reason}
                        """
    return user_prompt

def language_agent(objects, reason):

    # model_name = 'open-mixtral-8x7b'
    model_name = 'gpt-3.5-turbo'

    user_prompt_list = [generate_prompt(objects, reason)]
    response_total_list = []

    # 15000 tokens limit for gpt-3.5-turbo
    print('Count total tokens',count_total_tokens(user_prompt_list, response_total_list))
    if count_total_tokens(user_prompt_list, response_total_list) > 15000 and model_name in ['gpt-3.5-turbo',
                                                                                            'gpt-3.5-turbo-0125']:
        print('Total tokens exceed the limit of 15000 tokens for gpt-3.5-turbo')
        pass

    else:
        response_code = None
        while response_code == None:
            response_code = GPT_response("", model_name=model_name, user_prompt_list=user_prompt_list, response_total_list=response_total_list)
            print(response_code)
    result = re.findall(r'\d+', response_code)
    win=int(result[0])
    return win
